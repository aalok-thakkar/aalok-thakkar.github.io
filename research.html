<!DOCTYPE html>

	<head>

		<title> aalok thakkar |  research </title>

		<link rel="stylesheet" href="./webpage_files/style.css" type="text/css" media="screen">

	</head>

	<body>

		<div id="content">

			<h1>
				<a href="./index.html">aalok thakkar</a>: <strong>research</strong>
			</h1>

			<div style="border: 1px solid black; border-radius: 40px; padding: 10px; margin-left: 70px; margin-right: 70px; margin-bottom: 30px ; background-color: #F5F5DC; text-align: center;">
				<p>
					I have open research positions at Ashoka University (especially for undergraduate and PhD students). Please send me an
					<a href="mailto:athakkar@upenn.edu">email</a> if you are interested.
				</p>
				<p>
					Ashoka University students can find more information about undergraduate projects, capstone projects and
					thesis, and summer research <a href="./undergrad_research.html">here</a>.
				</p>
			</div>

			<div>

				<p>
					I am interested in formal methods and logic, and their applications to programming languages and artificial
					intelligence.
				</p>

				<div class="entry">

					<b> program synthesis:</b> Instead of writing a program directly, it is often easier to describe the intended behavior
					of a program in terms of either formal specification, natural language description, or input-output examples. Can we
					then translate these descriptions to program implementations? My prior work addresses this question in the context of 
					synthesizing relational queries from input-output examples by developing the example-guided synthesis paradigm. A
					good starting point for this work is <a href="./webpage_files/publications/thesis/thesis.pdf">my PhD thesis</a> or
					<a href="./webpage_files/publications/conference/pldi2021/pldi2021.pdf">EGS (PLDI 2021).</a> I am currently
					interested in extending example-guided synthesis to more expressive queries and other language domains. <br>
					<br>
					<b> reasoning in AI:</b> AGI (Artificial General Intelligence) requires robust reasoning capabilities and cannot
					solely rely on language generation methods. While current models excel at pattern recognition and text generation,
					they struggle with logical consistency and factual accuracy over longer contexts. On the other hand, symbolic
					reasoning excels at maintaining consistency and following strict rules, but struggles with the flexibility,
					creativity, and natural language understanding that neural networks provide. To leverage the best of both approaches,
					this line of work focuses on embedding formal reasoning tools within Large Language Models (LLMs). This integration
					aims to combine the strengths of data-driven language generation with logical inference, potentially leading to AI
					systems that can produce text that is not only fluent and contextually appropriate, but also logically sound and factually accurate across extended reasoning chains. <br>
					<br>
					<b> constrained generation:</b> This line of research explores techniques for generating text that complies with
					specific syntactic and semantic rules, formats, or requirements tailored to particular domains. The aim is to develop
					methods that can produce text adhering to strict guidelines or specialized formats, enhancing the precision and
					applicability of AI-generated content in specific fields or industries. This work seeks to improve the reliability and domain-specific relevance of AI-generated text.

				</div>
			</div>

		</div>

		<div id="footer">

			<p>
				<a href="./index.html">
					main
				</a>
				 :: 
				<a href="./publications.html">
					publications
				</a>
				:: 
				<a href="./research.html">
					research
				</a>
				:: 
				<a href="./contact.html">
					contact
				</a>
				:: 
				<a href="./teaching.html">
					teaching
				</a>
				 :: 
				<a href="./more.html">
					more
				</a>
			</p>

		</div>

	</body>

</html>